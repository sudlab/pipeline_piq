"""===========================
Pipeline template
===========================

.. Replace the documentation below with your own description of the
   pipeline's purpose

Overview
========

This pipeline computes the word frequencies in the configuration
files :file:``pipeline.yml` and :file:`conf.py`.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.yml` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_piq.py config

Input files
-----------

None required except the pipeline configuration files.

Requirements
------------

The pipeline requires the results from
:doc:`pipeline_genesets`. Set the configuration variable
:py:data:`annotations_database` and :py:data:`annotations_dir`.

On top of the default CGAT setup, the pipeline requires the following
software to be in the path:

.. Add any additional external requirements such as 3rd party software
   or R modules below:

Requirements:

* samtools >= 1.1

Pipeline output
===============

.. Describe output files of the pipeline here

Glossary
========

.. glossary::


Code
====

"""
import sys
import os
import CGATCore.IOTools as IOTools
import glob
import tempfile
import pipelinePIQ
from ruffus import transform, regex, suffix, follows, mkdir, split, formatter, collate
from ruffus.combinatorics import product


from CGATCore import Pipeline as P

# load options from the config file
PARAMS = P.get_parameters(
    ["%s/pipeline.yml" % os.path.splitext(__file__)[0],
     "../pipeline.yml",
     "pipeline.yml"])

PARAMS["COMMONSCRIPT"] = os.path.join(PARAMS["PIQ_PATH"], "common.r")


# Based on Copied from Motif_tools.motif_db_formatting_py3
# 
# Inputs:
#     -infile: A jaspar motif format file. Such as:
#        /shared/sudlab1/General/apps/bio/PIQ_human/pwms/jasparfix.txt
#
# >MA0001.1;AGL3
# A  [ 0  3 79 40 66 48 65 11 65  0 ]
# C  [94 75  4  3  1  2  5  2  3  3 ]
# G  [ 1  0  3  4  1  0  5  3 28 88 ]
# T  [ 2 19 11 50 29 47 22 81  1  6 ]
# >MA0002.1;RUNX1
# A  [10 12  4  1  2  2  0  0  0  8 13 ]
# C  [ 2  2  7  1  0  8  0  0  1  2  2 ]
# G  [ 3  1  1  0 23  0 26 26  0  0  4 ]
# T  [11 11 14 24  1 16  0  0 25 16  7 ]
#
# -number of motifs: Counts the number of lines beginning with ">"
#
# Outputs:
#     The number of motifs
def countMotifs(infile):
    
    num_motifs = 0
    
    with IOTools.open_file(infile, "r") as reader:
        
        for line in reader:

            # New motif
            if line.startswith(">"):
                
                num_motifs += 1
                
        return num_motifs
                
    reader.close()


# ---------------------------------------------------
# Specific pipeline tasks
@follows(mkdir("motif.matchs"))
@split(os.path.join(PARAMS["PIQ_PATH"], "pwms/jasparfix.txt"),
       ["motif.matchs/%i.pwmout.RData" % (i+1) for i in range(countMotifs(os.path.join(PARAMS["PIQ_PATH"], "pwms/jasparfix.txt")))])
def process_pwms(infile, outfiles):

    statements = []
    statement = []
    match_script = os.path.join(PARAMS["PIQ_PATH"], "pwmmatch.exact.r")
    out_dir = os.path.dirname(os.path.abspath(outfiles[0]))
    job_memory = "8G"
    
    statement_template = "Rscript %%(match_script)s %%(COMMONSCRIPT)s %%(infile)s %(i)i %%(out_dir)s"
    
    # Get the number of motifs in the file
    num_motifs_file = countMotifs(os.path.join(PARAMS["PIQ_PATH"], "pwms/jasparfix.txt"))
    
    for i in range(1,(num_motifs_file+1),1):
        statement.append(statement_template % locals())
        if len(statement) == PARAMS["chunk_size"]:
            statements.append("cd %(PIQ_PATH)s && "+ " && ".join(statement))
            statement = []

    statements.append( "&&".join(statement))
    
    P.run(statements, job_condaenv=PARAMS["piq_condaenv"])

@follows(mkdir("processed_bams.dir"))    
@transform("*.bam", formatter(), "processed_bams.dir/{basename[0]}.RData")
def process_bam(infile, outfile):

    infile = os.path.abspath(infile)
    outfile = os.path.abspath(outfile)
    bam2rdata_script = os.path.join(PARAMS["PIQ_PATH"], "bam2rdata.r")
    statement = '''cd %(PIQ_PATH)s &&
                   Rscript %(bam2rdata_script)s %(COMMONSCRIPT)s %(outfile)s %(infile)s'''
    job_memory = "64G"
    
    P.run(statement, job_condaenv=PARAMS["piq_condaenv"])


@follows(mkdir("calls.dir"))
@product(process_bam,
         formatter(),
         process_pwms,
         formatter("motif.matchs/(?P<PWM>.+).pwmout.RData"),
         "calls.dir/{basename[0][0]}/{PWM[1][0]}.done")
def call_matches(infiles, outfile):

    bamfile, pwm = infiles

    bamfile = os.path.abspath(bamfile)
    matchesdir = os.path.abspath(os.path.dirname(pwm))
    pwm_no = P.snip(os.path.basename(pwm), ".pwmout.RData")
    outfile = os.path.abspath(outfile)  
    pertf_script = os.path.join(PARAMS["PIQ_PATH"], "pertf.r")
    outdir = os.path.dirname(os.path.abspath(outfile))
    statement = '''cd %(PIQ_PATH)s &&
                   Rscript %(pertf_script)s 
                            %(COMMONSCRIPT)s 
                            %(matchesdir)s/  
                            $TMPDIR 
                            %(outdir)s 
                            %(bamfile)s
                            %(pwm_no)s &&
                  rm -rf $TMPDIR/* &&
                  touch %(outfile)s'''

    # Memory usage depends on input size

    size = os.path.getsize(pwm)
    size = size/(1024.0*1024.0)

    bamsize = os.path.getsize(bamfile)
    bamsize = bamsize/(1024.0*1024.0)

    if bamsize > 700:
        size += 15

    if size > 60:
        job_memory = "128G"
    elif size > 45:
        job_memory = "64G"    
    elif size > 30:
        job_memory = "32G"
    elif size > 15:
        job_memory = "16G"
    elif size > 5:
        job_memory = "8G"
    else:
        job_memory = "4G"

    P.run(statement, job_condaenv = PARAMS["piq_condaenv"])
    
    


@follows(call_matches,
         mkdir("calls_filtered.dir"))
@collate("calls.dir/*/*-calls.*",
           formatter("calls.dir/(?P<SAMPLE>.+)/(?P<PWM>.+?)(\.RC|)-calls\..*"),
           "calls_filtered.dir/{SAMPLE[0]}/{PWM[0]}-calls.sign.bed.gz",
           "{SAMPLE[0]}",
           "{PWM[0]}")
def filter_matches(infiles, outfile, sample, pwm):
    
   
    if(len(infiles) != 6):
        raise Exception("All the call files are not produced")
    
    # If the directory for the sample doesn't exist, create it
    if not os.path.exists(os.path.dirname(outfile)):
        os.makedirs(os.path.dirname(outfile))

    
    # Get the different files
    calls_all_file=""
    RC_calls_all_file=""
    calls_sign_file=""
    RC_calls_sign_file=""
    
    for infile in infiles:
        if infile.endswith("-calls.all.bed"):
            if infile.endswith(".RC-calls.all.bed"):
                RC_calls_all_file=infile
            else:
                calls_all_file=infile
        
        elif infile.endswith("-calls.csv"):
            if infile.endswith(".RC-calls.csv"):
                RC_calls_sign_file=infile
            else:
                calls_sign_file=infile
    
    # Get the temp dir        
    tmp_dir = PARAMS["shared_tmpdir"]
    
    # Temp file: We create a temp file to make sure the whole process goes well
    # before the actual outfile is created
    
    # Processing of the files containing all calls
    temp_file_all_calls = (tempfile.NamedTemporaryFile(dir=tmp_dir, delete=False)).name
    
    temp_file_all_calls_RC = (tempfile.NamedTemporaryFile(dir=tmp_dir, delete=False)).name

    # Processing of the
    temp_file_calls_sign = (tempfile.NamedTemporaryFile(dir=tmp_dir, delete=False)).name
    
    temp_file_calls_sign_RC = (tempfile.NamedTemporaryFile(dir=tmp_dir, delete=False)).name
    
    
            
    # The first step is to remove the header from both files and filter individually the
    # significant motifs
    # Output the rest of the file adding a numeric count starting at 1
    statement = '''cat %(calls_all_file)s | tail -n +2 | awk 'BEGIN {FS ="\\t"} {printf("%%s\\t%%s\\n", NR, $0)}' | gzip > %(temp_file_all_calls)s  &&
        
    cat %(RC_calls_all_file)s | tail -n +2 | awk 'BEGIN {FS ="\\t"} {printf("%%s\\t%%s\\n", NR, $0)}' | gzip > %(temp_file_all_calls_RC)s  &&
    
    cat %(calls_sign_file)s | tail -n +2 | sed -e 's/,/\\t/g' | cut -f 1 | sed -e 's/"//g' | gzip > %(temp_file_calls_sign)s  &&
        
    cat %(RC_calls_sign_file)s | tail -n +2 | sed -e 's/,/\\t/g' | cut -f 1 | sed -e 's/"//g' | gzip > %(temp_file_calls_sign_RC)s '''
    
    P.run(statement)
    
    
    # Processing of the bed files to select significant calls
    temp_file_calls_sign_bed = (tempfile.NamedTemporaryFile(dir=tmp_dir, delete=False)).name
    
    temp_file_calls_sign_bed_RC = (tempfile.NamedTemporaryFile(dir=tmp_dir, delete=False)).name
    
    # Now merge the tables to select only significant calls in bed format
    pipelinePIQ.filterSignCalls(temp_file_all_calls,
                    temp_file_calls_sign,
                    temp_file_calls_sign_bed)
    
    pipelinePIQ.filterSignCalls(temp_file_all_calls_RC,
                    temp_file_calls_sign_RC,
                    temp_file_calls_sign_bed_RC)
    
    
    # Create temp output
    temp_output = (tempfile.NamedTemporaryFile(dir=tmp_dir, delete=False)).name
    
    
    
    # Now concatenate both bed files and sort by chr and start
    # Delete all temporal files 

    statement = '''zcat %(temp_file_calls_sign_bed)s %(temp_file_calls_sign_bed_RC)s | sort -k 1,1 -k2,2n | gzip > %(temp_output)s && 
    rm %(temp_file_all_calls)s %(temp_file_all_calls_RC)s %(temp_file_calls_sign)s %(temp_file_calls_sign_RC)s %(temp_file_calls_sign_bed)s %(temp_file_calls_sign_bed_RC)s && 
    mv %(temp_output)s %(outfile)s '''
    
    P.run(statement)
    

   
       



# ---------------------------------------------------
# Generic pipeline tasks
@follows(filter_matches)
def full():
    pass


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))    
